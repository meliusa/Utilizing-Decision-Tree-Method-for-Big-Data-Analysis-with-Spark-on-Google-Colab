{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/meliusa/Utilizing-Decision-Tree-Method-for-Big-Data-Analysis-with-Spark-on-Google-Colab/blob/main/Utilizing_Decision_Tree_Method_for_Big_Data_Analysis_with_Spark_on_Google_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TI-3G :\n",
        "- Meliusa Nora Hariyanti\n",
        "- Dherisma Hanindita Utami\n",
        "\n"
      ],
      "metadata": {
        "id": "XaTTG8hY5nRj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "install library pyspark ke google colab"
      ],
      "metadata": {
        "id": "1C8bwYl_yckO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U2vOaU3MvvqF",
        "outputId": "97266d73-b9eb-4213-e826-8cde7994cb89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.4.0.tar.gz (310.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.8/310.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.4.0-py2.py3-none-any.whl size=311317130 sha256=f4ba0ef6241ae035135c9316f1f23efbe4ee751afa8b6612b3a87979d6fafda6\n",
            "  Stored in directory: /root/.cache/pip/wheels/7b/1b/4b/3363a1d04368e7ff0d408e57ff57966fcdf00583774e761327\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "import library SparkSession dan DecisionTreeClassifier:"
      ],
      "metadata": {
        "id": "uqbk4Xf3yib6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rWKR8Bj0vfV1"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.classification import DecisionTreeClassifier"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "buat sesi SparkSession:"
      ],
      "metadata": {
        "id": "C3cF-pYeyn0h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder.appName(\"DecisionTreeExample\").getOrCreate()"
      ],
      "metadata": {
        "id": "BHrMyjs3vnEc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "load dataset"
      ],
      "metadata": {
        "id": "p2KR0FGayrAs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"data.csv\")"
      ],
      "metadata": {
        "id": "IonjGqBkwPyp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "pemrosesan dan persiapan data\n",
        "1. jika diperlukan, lakukan pemrosesan data seperti pembersihan, pengubahan format, dan pemilihan fitur yang relevan.\n",
        "2. pisahkan data menjadi data pelatihan (train) dan data pengujian (test):"
      ],
      "metadata": {
        "id": "EFHRHIu1ywxG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(trainData, testData) = dataset.randomSplit([0.7, 0.3])"
      ],
      "metadata": {
        "id": "h4LkINJfwZ2h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "definisikan model Decision Tree:"
      ],
      "metadata": {
        "id": "qihylPqpzDS7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dt = DecisionTreeClassifier(labelCol=\"quality\", featuresCol=\"fixed acidity\")"
      ],
      "metadata": {
        "id": "52HZVvgOwbXC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "kita convert dulu type variabelnya ke float agar bisa di proses"
      ],
      "metadata": {
        "id": "kKILLGW6zKTi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.sql.functions import col"
      ],
      "metadata": {
        "id": "ygW2Ntikw4lx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assembler = VectorAssembler(inputCols=trainData.columns[:-1], outputCol=\"last1\")\n"
      ],
      "metadata": {
        "id": "NLtttMjdxNab"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainData = trainData.withColumn(\"volatile acidity\", trainData[\"volatile acidity\"].cast(\"float\"))\n",
        "trainData = trainData.withColumn(\"citric acid\", trainData[\"citric acid\"].cast(\"float\"))\n",
        "trainData = trainData.withColumn(\"residual sugar\", trainData[\"residual sugar\"].cast(\"float\"))\n",
        "trainData = trainData.withColumn(\"chlorides\", trainData[\"chlorides\"].cast(\"float\"))\n",
        "trainData = trainData.withColumn(\"free sulfur dioxide\", trainData[\"free sulfur dioxide\"].cast(\"float\"))\n",
        "trainData = trainData.withColumn(\"total sulfur dioxide\", trainData[\"total sulfur dioxide\"].cast(\"float\"))\n",
        "trainData = trainData.withColumn(\"density\", trainData[\"density\"].cast(\"float\"))\n",
        "trainData = trainData.withColumn(\"pH\", trainData[\"pH\"].cast(\"float\"))\n",
        "trainData = trainData.withColumn(\"sulphates\", trainData[\"sulphates\"].cast(\"float\"))\n",
        "trainData = trainData.withColumn(\"alcohol\", trainData[\"alcohol\"].cast(\"float\"))\n",
        "trainData = trainData.withColumn(\"quality\", trainData[\"quality\"].cast(\"float\"))\n"
      ],
      "metadata": {
        "id": "FGYMP_Efxld-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "transformasikan DataFrame \"trainData\" menggunakan VectorAssembler:"
      ],
      "metadata": {
        "id": "QW0-Qb2GzYe7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainData = assembler.transform(trainData)"
      ],
      "metadata": {
        "id": "A8ioIF0QxPi8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "latih model menggunakan data pelatihan:"
      ],
      "metadata": {
        "id": "kJzLhlFozcYF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = dt.fit(trainData)"
      ],
      "metadata": {
        "id": "SKqbaKdjxuDO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "lakukan prediksi menggunakan data pengujian:"
      ],
      "metadata": {
        "id": "iRyJwDehzeqw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.transform(trainData)"
      ],
      "metadata": {
        "id": "BJ-h0ybKyBLC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "evaluasi performa model, misalnya dengan menggunakan metrik evaluasi seperti akurasi, presisi, atau recall:"
      ],
      "metadata": {
        "id": "h-d8evfwzgus"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"quality\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "print(\"Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5r766EefyOZF",
        "outputId": "613b3799-b59b-431e-ead1-994857fe8556"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6518650088809946\n"
          ]
        }
      ]
    }
  ]
}